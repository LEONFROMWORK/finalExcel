# frozen_string_literal: true

# Excel ë°ì´í„°ë¥¼ LLMì´ ì´í•´í•˜ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë¸Œë¦¿ì§€ ì„œë¹„ìŠ¤
class ExcelLLMBridgeService
  MAX_CELLS_FOR_CONTEXT = 1000  # LLM ì»¨í…ìŠ¤íŠ¸ ì œí•œì„ ìœ„í•œ ìµœëŒ€ ì…€ ìˆ˜
  MAX_PREVIEW_ROWS = 20         # ë¯¸ë¦¬ë³´ê¸° ìµœëŒ€ í–‰ ìˆ˜
  
  def initialize(excel_file)
    @excel_file = excel_file
    @python_client = PythonServiceClient.new
  end
  
  # Excel íŒŒì¼ì„ LLMì´ ì´í•´í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
  def serialize_for_llm(options = {})
    focus_area = options[:focus_area]  # íŠ¹ì • ì‹œíŠ¸ë‚˜ ë²”ìœ„ì— ì§‘ì¤‘
    include_formulas = options[:include_formulas] != false
    include_formatting = options[:include_formatting] || false
    
    data = fetch_excel_data(focus_area)
    
    {
      summary: create_summary(data),
      structure: serialize_structure(data),
      sample_data: serialize_sample_data(data, include_formulas),
      formulas: include_formulas ? serialize_formulas(data) : nil,
      formatting: include_formatting ? serialize_formatting(data) : nil,
      issues: serialize_issues(data),
      metadata: serialize_metadata
    }
  end
  
  # íŠ¹ì • ë¬¸ì œì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
  def create_problem_context(problem_description, options = {})
    # ë¬¸ì œì™€ ê´€ë ¨ëœ ë°ì´í„°ë§Œ ì¶”ì¶œ
    relevant_data = extract_relevant_data(problem_description)
    
    context = {
      problem: problem_description,
      file_overview: create_summary(relevant_data),
      related_sheets: find_related_sheets(problem_description, relevant_data),
      relevant_formulas: find_relevant_formulas(problem_description, relevant_data),
      data_sample: create_focused_sample(relevant_data, problem_description),
      detected_patterns: detect_patterns(relevant_data)
    }
    
    # í† í° ì œí•œì„ ê³ ë ¤í•œ ì••ì¶•
    compress_context(context, options[:max_tokens] || 4000)
  end
  
  # LLM ì‘ë‹µì„ Excel ì‘ì—…ìœ¼ë¡œ ë³€í™˜
  def parse_llm_solution(llm_response, context = {})
    solution = {
      modifications: [],
      formulas: [],
      formatting: [],
      validations: [],
      explanations: []
    }
    
    # ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ
    code_blocks = extract_code_blocks(llm_response)
    
    code_blocks.each do |block|
      case block[:language]
      when 'excel', 'formula'
        solution[:formulas] += parse_excel_formulas(block[:code])
      when 'python'
        solution[:modifications] += parse_python_modifications(block[:code], context)
      when 'json'
        solution[:modifications] += parse_json_modifications(block[:code])
      end
    end
    
    # í…ìŠ¤íŠ¸ ì„¤ëª…ì—ì„œ ì‘ì—… ì¶”ì¶œ
    solution[:explanations] = extract_explanations(llm_response)
    
    # ì‹¤í–‰ ê°€ëŠ¥í•œ ì‘ì—…ìœ¼ë¡œ ë³€í™˜
    convert_to_executable_actions(solution)
  end
  
  # ì´ë¯¸ì§€ì™€ Excel ë°ì´í„° ì—°ê´€ ë¶„ì„
  def correlate_with_image(image_analysis_result)
    excel_data = fetch_excel_data
    
    correlation = {
      matched_data: [],
      discrepancies: [],
      suggestions: []
    }
    
    # ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ í‘œì™€ Excel ì‹œíŠ¸ ë§¤ì¹­
    if image_analysis_result['tables']
      image_analysis_result['tables'].each do |img_table|
        matched_sheet = find_matching_sheet(img_table, excel_data)
        
        if matched_sheet
          correlation[:matched_data] << {
            image_table: img_table,
            excel_sheet: matched_sheet[:name],
            similarity_score: matched_sheet[:score],
            differences: compare_data(img_table, matched_sheet[:data])
          }
        else
          correlation[:discrepancies] << {
            image_table: img_table,
            suggestion: suggest_sheet_creation(img_table)
          }
        end
      end
    end
    
    # ì°¨íŠ¸ ë°ì´í„° ì—°ê´€ì„± ë¶„ì„
    if image_analysis_result['charts']
      correlation[:chart_analysis] = analyze_chart_correlation(
        image_analysis_result['charts'],
        excel_data
      )
    end
    
    correlation[:suggestions] = generate_correlation_suggestions(correlation)
    correlation
  end
  
  private
  
  def fetch_excel_data(focus_area = nil)
    # Python ì„œë¹„ìŠ¤ì—ì„œ ìƒì„¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    file_path = get_file_path(@excel_file)
    
    @python_client.get_detailed_analysis(file_path, {
      focus_area: focus_area,
      include_values: true,
      include_formulas: true,
      include_formatting: true
    })
  rescue StandardError => e
    Rails.logger.error "Failed to fetch Excel data: #{e.message}"
    @excel_file.analysis_result || {}
  end
  
  def create_summary(data)
    summary = []
    
    summary << "ğŸ“Š Excel File Overview:"
    summary << "- Filename: #{@excel_file.filename}"
    summary << "- Total Sheets: #{data['sheets']&.size || 0}"
    summary << "- File Size: #{format_file_size(@excel_file.file_size)}"
    
    if data['summary']
      summary << "- Total Rows: #{data['summary']['total_rows']}"
      summary << "- Total Columns: #{data['summary']['total_columns']}"
      summary << "- Formulas: #{data['summary']['total_formulas']}"
      summary << "- Charts: #{data['summary']['total_charts'] || 0}"
    end
    
    if data['errors']&.any?
      summary << "\nâš ï¸ Issues Found: #{data['errors'].size} errors"
    end
    
    summary.join("\n")
  end
  
  def serialize_structure(data)
    return {} unless data['sheets']
    
    structure = {}
    
    data['sheets'].each do |sheet|
      structure[sheet['name']] = {
        dimensions: "#{sheet['rows']}x#{sheet['columns']}",
        headers: sheet['headers'] || detect_headers(sheet),
        data_types: sheet['data_types'] || {},
        has_formulas: sheet['formula_count'] > 0,
        has_charts: sheet['charts']&.any? || false,
        named_ranges: sheet['named_ranges'] || []
      }
    end
    
    structure
  end
  
  def serialize_sample_data(data, include_formulas)
    samples = {}
    
    data['sheets']&.each do |sheet|
      next unless sheet['sample_data']
      
      samples[sheet['name']] = {
        preview: format_data_preview(sheet['sample_data'], MAX_PREVIEW_ROWS),
        column_stats: calculate_column_stats(sheet['sample_data']),
        formulas: include_formulas ? extract_sample_formulas(sheet) : nil
      }
    end
    
    samples
  end
  
  def serialize_formulas(data)
    formulas = {
      by_type: {},
      complex_formulas: [],
      dependencies: {}
    }
    
    data['sheets']&.each do |sheet|
      next unless sheet['formulas']
      
      sheet['formulas'].each do |formula_info|
        # ìˆ˜ì‹ íƒ€ì…ë³„ ë¶„ë¥˜
        formula_type = detect_formula_type(formula_info['formula'])
        formulas[:by_type][formula_type] ||= []
        formulas[:by_type][formula_type] << {
          sheet: sheet['name'],
          cell: formula_info['cell'],
          formula: formula_info['formula']
        }
        
        # ë³µì¡í•œ ìˆ˜ì‹ ì‹ë³„
        if is_complex_formula?(formula_info['formula'])
          formulas[:complex_formulas] << formula_info.merge(sheet: sheet['name'])
        end
        
        # ì˜ì¡´ì„± ë¶„ì„
        deps = extract_formula_dependencies(formula_info['formula'])
        if deps.any?
          formulas[:dependencies][formula_info['cell']] = deps
        end
      end
    end
    
    formulas
  end
  
  def extract_relevant_data(problem_description)
    keywords = extract_keywords(problem_description)
    
    data = fetch_excel_data
    relevant = {
      'sheets' => [],
      'summary' => data['summary'],
      'errors' => []
    }
    
    # í‚¤ì›Œë“œì™€ ë§¤ì¹­ë˜ëŠ” ì‹œíŠ¸ ì°¾ê¸°
    data['sheets']&.each do |sheet|
      relevance_score = calculate_relevance(sheet, keywords)
      if relevance_score > 0.3
        relevant['sheets'] << sheet.merge('relevance_score' => relevance_score)
      end
    end
    
    # ê´€ë ¨ ì˜¤ë¥˜ ì°¾ê¸°
    data['errors']&.each do |error|
      if keywords.any? { |kw| error['description']&.downcase&.include?(kw.downcase) }
        relevant['errors'] << error
      end
    end
    
    relevant
  end
  
  def find_matching_sheet(img_table, excel_data)
    best_match = nil
    best_score = 0
    
    excel_data['sheets']&.each do |sheet|
      score = calculate_table_similarity(img_table, sheet)
      
      if score > best_score && score > 0.7  # 70% ìœ ì‚¬ë„ ì„ê³„ê°’
        best_match = {
          name: sheet['name'],
          data: sheet,
          score: score
        }
        best_score = score
      end
    end
    
    best_match
  end
  
  def calculate_table_similarity(img_table, sheet)
    score = 0.0
    factors = 0
    
    # í¬ê¸° ë¹„êµ
    if img_table['rows'] && sheet['rows']
      size_diff = (img_table['rows'] - sheet['rows']).abs.to_f / [img_table['rows'], sheet['rows']].max
      score += (1 - size_diff) * 0.3
      factors += 0.3
    end
    
    # í—¤ë” ë¹„êµ
    if img_table['headers'] && sheet['headers']
      header_similarity = calculate_text_similarity(img_table['headers'], sheet['headers'])
      score += header_similarity * 0.5
      factors += 0.5
    end
    
    # ë°ì´í„° ìƒ˜í”Œ ë¹„êµ
    if img_table['sample_data'] && sheet['sample_data']
      data_similarity = calculate_data_similarity(img_table['sample_data'], sheet['sample_data'])
      score += data_similarity * 0.2
      factors += 0.2
    end
    
    factors > 0 ? score / factors : 0
  end
  
  def compare_data(img_table, excel_sheet_data)
    differences = []
    
    # í—¤ë” ì°¨ì´
    if img_table['headers'] && excel_sheet_data['headers']
      img_headers = img_table['headers']
      excel_headers = excel_sheet_data['headers']
      
      missing_in_excel = img_headers - excel_headers
      missing_in_image = excel_headers - img_headers
      
      if missing_in_excel.any?
        differences << {
          type: 'missing_headers',
          location: 'excel',
          values: missing_in_excel
        }
      end
      
      if missing_in_image.any?
        differences << {
          type: 'missing_headers',
          location: 'image',
          values: missing_in_image
        }
      end
    end
    
    # ë°ì´í„° ê°’ ì°¨ì´
    if img_table['sample_data'] && excel_sheet_data['sample_data']
      value_differences = find_value_differences(
        img_table['sample_data'],
        excel_sheet_data['sample_data']
      )
      differences.concat(value_differences)
    end
    
    differences
  end
  
  def suggest_sheet_creation(img_table)
    {
      action: 'create_sheet',
      sheet_name: suggest_sheet_name(img_table),
      structure: {
        headers: img_table['headers'],
        data_types: infer_data_types(img_table['sample_data']),
        initial_data: img_table['sample_data']
      }
    }
  end
  
  def generate_correlation_suggestions(correlation)
    suggestions = []
    
    # ë§¤ì¹­ëœ ë°ì´í„°ì— ëŒ€í•œ ì œì•ˆ
    correlation[:matched_data]&.each do |match|
      if match[:differences].any?
        suggestions << {
          type: 'sync_data',
          priority: 'high',
          description: "Sync differences between image and #{match[:excel_sheet]}",
          actions: generate_sync_actions(match[:differences])
        }
      end
    end
    
    # ë¶ˆì¼ì¹˜ ë°ì´í„°ì— ëŒ€í•œ ì œì•ˆ
    correlation[:discrepancies]&.each do |discrepancy|
      suggestions << {
        type: 'create_missing',
        priority: 'medium',
        description: "Create new sheet from image data",
        action: discrepancy[:suggestion]
      }
    end
    
    suggestions
  end
  
  def convert_to_executable_actions(solution)
    actions = []
    
    # ìˆ˜ì‹ ì¶”ê°€/ìˆ˜ì •
    solution[:formulas].each do |formula|
      actions << {
        type: 'update_cell',
        cell: formula[:cell],
        value: formula[:formula],
        sheet: formula[:sheet]
      }
    end
    
    # ë°ì´í„° ìˆ˜ì •
    solution[:modifications].each do |mod|
      actions << normalize_modification(mod)
    end
    
    # ê²€ì¦ ê°€ëŠ¥í•œ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    actions.map { |action| validate_and_enhance_action(action) }
  end
  
  def compress_context(context, max_tokens)
    estimated_tokens = estimate_tokens(context.to_json)
    
    if estimated_tokens > max_tokens
      # í† í° ì´ˆê³¼ ì‹œ ì••ì¶• ì „ëµ
      context[:data_sample] = reduce_sample_size(context[:data_sample])
      context[:relevant_formulas] = context[:relevant_formulas]&.first(20)
      context[:related_sheets] = context[:related_sheets]&.first(3)
    end
    
    context
  end
  
  def extract_keywords(text)
    # ì¤‘ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
    keywords = text.downcase.scan(/\b\w+\b/)
                   .reject { |w| w.length < 3 }
                   .reject { |w| STOP_WORDS.include?(w) }
    
    # Excel ê´€ë ¨ íŠ¹ìˆ˜ í‚¤ì›Œë“œ ì¶”ê°€
    excel_keywords = []
    excel_keywords << 'sum' if text.match?(/í•©ê³„|sum|total/i)
    excel_keywords << 'vlookup' if text.match?(/vlookup|ì°¾ê¸°|ê²€ìƒ‰/i)
    excel_keywords << 'pivot' if text.match?(/pivot|í”¼ë²—/i)
    
    (keywords + excel_keywords).uniq
  end
  
  def calculate_relevance(sheet, keywords)
    score = 0.0
    
    # ì‹œíŠ¸ ì´ë¦„ ë§¤ì¹­
    keywords.each do |keyword|
      score += 0.3 if sheet['name'].downcase.include?(keyword)
    end
    
    # í—¤ë” ë§¤ì¹­
    if sheet['headers']
      matching_headers = sheet['headers'].count { |h| 
        keywords.any? { |k| h.downcase.include?(k) }
      }
      score += (matching_headers.to_f / sheet['headers'].size) * 0.4
    end
    
    # ë°ì´í„° ë‚´ìš© ë§¤ì¹­ (ìƒ˜í”Œ)
    if sheet['sample_data']
      # ìƒ˜í”Œ ë°ì´í„°ì—ì„œ í‚¤ì›Œë“œ ì¶œí˜„ ë¹ˆë„
      keyword_frequency = calculate_keyword_frequency(sheet['sample_data'], keywords)
      score += [keyword_frequency * 0.3, 0.3].min
    end
    
    [score, 1.0].min
  end
  
  def format_file_size(bytes)
    return '0 Bytes' if bytes == 0
    
    k = 1024
    sizes = ['Bytes', 'KB', 'MB', 'GB']
    i = (Math.log(bytes) / Math.log(k)).floor
    
    "#{(bytes.to_f / (k**i)).round(2)} #{sizes[i]}"
  end
  
  def get_file_path(excel_file)
    if excel_file.file_url.start_with?('/')
      Rails.root.join('tmp', 'uploads', File.basename(excel_file.file_url))
    else
      ActiveStorage::Blob.service.path_for(excel_file.file_url)
    end
  end
  
  def estimate_tokens(text)
    # ê°„ë‹¨í•œ í† í° ì¶”ì • (ì‹¤ì œë¡œëŠ” tiktoken ì‚¬ìš©)
    text.split(/\s+/).size * 1.3
  end
  
  STOP_WORDS = %w[the is at which on a an as are was were been be have has had do does did will would could should may might must shall can].freeze
  
  def detect_formula_type(formula)
    case formula
    when /^=SUM\(/i then 'aggregation'
    when /^=AVERAGE|MEDIAN|MODE/i then 'statistical'
    when /^=VLOOKUP|HLOOKUP|INDEX|MATCH/i then 'lookup'
    when /^=IF|IFS|SWITCH/i then 'conditional'
    when /^=COUNT|COUNTA|COUNTIF/i then 'counting'
    else 'other'
    end
  end
  
  def is_complex_formula?(formula)
    # ì¤‘ì²© í•¨ìˆ˜, ë°°ì—´ ìˆ˜ì‹, ê¸´ ìˆ˜ì‹ ë“±
    formula.count('(') > 3 || formula.length > 100 || formula.include?('ARRAY')
  end
  
  def detect_column_types(values)
    types = values.map { |v| detect_value_type(v) }
    
    # ê°€ì¥ ë§ì€ íƒ€ì… ë°˜í™˜
    type_counts = types.tally
    primary_type = type_counts.max_by { |_, count| count }&.first || 'text'
    
    {
      primary: primary_type,
      distribution: type_counts,
      mixed: type_counts.size > 1
    }
  end
  
  def detect_value_type(value)
    return 'empty' if value.nil? || value.to_s.strip.empty?
    
    # ìˆ«ì ê²€ì‚¬
    if value.is_a?(Numeric) || value.to_s =~ /^-?\d+\.?\d*$/
      'number'
    # ë‚ ì§œ ê²€ì‚¬
    elsif value.is_a?(Date) || value.is_a?(Time) || value.to_s =~ /^\d{4}-\d{2}-\d{2}/
      'date'
    # ìˆ˜ì‹ ê²€ì‚¬
    elsif value.to_s.start_with?('=')
      'formula'
    # ë¶ˆë¦° ê²€ì‚¬
    elsif %w[true false TRUE FALSE].include?(value.to_s)
      'boolean'
    else
      'text'
    end
  end
  
  def likely_headers?(first_row, data_rows)
    return false if first_row.nil? || data_rows.empty?
    
    # ì²« ë²ˆì§¸ í–‰ì´ í…ìŠ¤íŠ¸ì´ê³  ë‚˜ë¨¸ì§€ í–‰ê³¼ ë‹¤ë¥¸ íƒ€ì…ì¸ì§€ í™•ì¸
    first_row_types = first_row.map { |v| detect_value_type(v) }
    
    # ëª¨ë“  ê°’ì´ í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
    all_text = first_row_types.all? { |t| t == 'text' }
    
    # ë°ì´í„° í–‰ì˜ íƒ€ì…ê³¼ ë¹„êµ
    data_row_types = data_rows.first(5).flat_map { |row| 
      row.map { |v| detect_value_type(v) } 
    }.tally
    
    # ì²« í–‰ì´ ëŒ€ë¶€ë¶„ í…ìŠ¤íŠ¸ì´ê³  ë°ì´í„° í–‰ì€ í˜¼í•© íƒ€ì…ì´ë©´ í—¤ë”ì¼ ê°€ëŠ¥ì„± ë†’ìŒ
    all_text && data_row_types.keys.size > 1
  end
  
  def extract_operation_type(code)
    case code
    when /pivot_table/i then 'pivot'
    when /groupby/i then 'group'
    when /merge/i then 'merge'
    when /concat/i then 'concatenate'
    when /filter/i then 'filter'
    when /sort/i then 'sort'
    else 'transform'
    end
  end
  
  def normalize_json_modification(mod)
    {
      type: mod['type'] || 'update',
      cell: mod['cell'] || mod['address'],
      value: mod['value'],
      sheet: mod['sheet'] || 'Sheet1',
      description: mod['description']
    }
  end
  
  def calculate_row_similarity(row1, row2)
    return 0.0 if row1.nil? || row2.nil?
    
    matches = 0
    comparisons = 0
    
    [row1.size, row2.size].min.times do |i|
      comparisons += 1
      if normalize_value(row1[i]) == normalize_value(row2[i])
        matches += 1
      end
    end
    
    comparisons > 0 ? matches.to_f / comparisons : 0.0
  end
  
  def normalize_value(value)
    value.to_s.downcase.strip.gsub(/\s+/, ' ')
  end
  
  def normalize_cell_reference(cell_ref)
    # A1 -> A1, sheet1!A1 -> Sheet1!A1, etc.
    cell_ref.to_s.upcase.strip
  end
  
  def validate_action_executable(action)
    case action[:type]
    when 'update_cell'
      !action[:cell].nil? && !action[:value].nil?
    when 'insert_row', 'insert_column', 'delete_row', 'delete_column'
      !action[:position].nil?
    else
      true
    end
  end
  
  def analyze_chart_correlation(charts, excel_data)
    correlations = []
    
    charts.each do |chart|
      # ì°¨íŠ¸ ë°ì´í„°ì™€ Excel ë°ì´í„° ë¹„êµ
      if chart['data_points']
        matching_data = find_matching_data_series(chart['data_points'], excel_data)
        
        correlations << {
          chart_type: chart['type'],
          chart_title: chart['title'],
          matched_sheets: matching_data,
          confidence: calculate_chart_confidence(matching_data)
        }
      end
    end
    
    correlations
  end
  
  def find_matching_data_series(data_points, excel_data)
    matches = []
    
    excel_data['sheets']&.each do |sheet|
      if sheet['sample_data']
        # ë°ì´í„° ì‹œë¦¬ì¦ˆ ë§¤ì¹­ ë¡œì§
        similarity = calculate_series_similarity(data_points, sheet['sample_data'])
        
        if similarity > 0.5
          matches << {
            sheet: sheet['name'],
            similarity: similarity,
            data_range: suggest_data_range(sheet)
          }
        end
      end
    end
    
    matches
  end
  
  def calculate_series_similarity(series1, series2)
    # ê°„ë‹¨í•œ ì‹œë¦¬ì¦ˆ ìœ ì‚¬ë„ ê³„ì‚°
    0.7  # ì„ì‹œ êµ¬í˜„
  end
  
  def calculate_chart_confidence(matches)
    return 0.0 if matches.empty?
    
    # ìµœê³  ë§¤ì¹­ ì ìˆ˜ ë°˜í™˜
    matches.map { |m| m[:similarity] }.max
  end
  
  def suggest_data_range(sheet)
    # ë°ì´í„° ë²”ìœ„ ì¶”ì²œ
    rows = sheet['rows'] || 0
    cols = sheet['columns'] || 0
    
    "A1:#{('A'.ord + cols - 1).chr}#{rows}"
  end
  
  def calculate_keyword_frequency(data, keywords)
    return 0.0 unless data && keywords.any?
    
    total_cells = 0
    keyword_matches = 0
    
    data.each do |row|
      row.each do |cell|
        cell_text = cell.to_s.downcase
        total_cells += 1
        
        if keywords.any? { |kw| cell_text.include?(kw.downcase) }
          keyword_matches += 1
        end
      end
    end
    
    total_cells > 0 ? keyword_matches.to_f / total_cells : 0.0
  end
end